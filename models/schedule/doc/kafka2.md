# ä¼ä¸šå¾®ä¿¡å®¢æœæ¶ˆæ¯ç³»ç»Ÿ Kafka é›†æˆæ–¹æ¡ˆï¼ˆJennyæ¶æ„é‡æ„ç‰ˆï¼‰

## å˜æ›´æ‘˜è¦ï¼ˆJennyæ¶æ„é‡æ„ï¼‰

**ğŸ¯ æ ¸å¿ƒä¿®æ­£**ï¼šæ¶ˆé™¤åŸè®¾è®¡ä¸­çš„**è‡´å‘½é”™è¯¯**å’Œ**è¿‡åº¦å¤æ‚æ€§**ï¼Œå›å½’Kafkaä½¿ç”¨çš„æœ¬è´¨ã€‚

### ğŸ”´ ä¿®å¤çš„è‡´å‘½é—®é¢˜
1. **åˆ†åŒºå†…è¿ç»­æäº¤é—®é¢˜**ï¼šå¼•å…¥`PartitionCommitGate`ï¼Œè§£å†³"é«˜offsetå…ˆæäº¤è·³è¿‡ä½offset"çš„ä¸¢æ¶ˆæ¯é—®é¢˜
2. **é…ç½®é”®é”™è¯¯**ï¼šä½¿ç”¨`librdkafka`æ­£ç¡®çš„é…ç½®é”®ï¼ˆ`message.send.max.retries`è€Œé`retries`ï¼‰
3. **åˆ†åŒºå™¨ä¸ä¸€è‡´**ï¼šç»Ÿä¸€ä½¿ç”¨`murmur2_random`ä¿è¯è·¨è¯­è¨€åˆ†åŒºä¸€è‡´æ€§

### ğŸŸ¡ ç®€åŒ–çš„æ¶æ„å¤æ‚æ€§
1. **æ¶ˆé™¤ç‰¹æ®Šæƒ…å†µå¤„ç†**ï¼šåºŸé™¤å¤æ‚çš„é™çº§é€»è¾‘ã€å¤šå±‚ç†”æ–­å™¨ã€UserProcessorçŠ¶æ€æœº
2. **DLQæç®€åŒ–**ï¼šä»å¤æ‚çš„æ¢å¤ç­–ç•¥ç³»ç»Ÿç®€åŒ–ä¸ºæ ‡å‡†çš„æ­»ä¿¡é˜Ÿåˆ—
3. **é…ç½®ç»Ÿä¸€**ï¼šåŸºäº`confluent-kafka-go`ä»“åº“çš„æ ‡å‡†å®è·µ

### ğŸŸ¢ é‡‡ç”¨çš„æœ€ä½³å®è·µ
1. **æ•°æ®ç»“æ„ä¼˜å…ˆ**ï¼š`PartitionCommitGate`ä½œä¸ºæ ¸å¿ƒæ•°æ®ç»“æ„è§£å†³æ‰€æœ‰æäº¤é—®é¢˜
2. **å®ç”¨ä¸»ä¹‰è®¾è®¡**ï¼šç›´æ¥ä½¿ç”¨`kmq`åŒ…è£…å±‚ï¼Œé¿å…è¿‡åº¦æŠ½è±¡
3. **é›¶ç ´åæ€§è¿ç§»**ï¼šä¿æŒAPIå…¼å®¹ï¼Œåªä¿®æ”¹å†…éƒ¨å®ç°
4. **ä¸‰çº§é™çº§ä¿æŠ¤**ï¼šKafka â†’ DLQ â†’ MySQLï¼Œç¡®ä¿æ¶ˆæ¯æ°¸ä¸ä¸¢å¤±ï¼ˆMySQLéƒ¨åˆ†TODOï¼‰

---

## 1. æ¶æ„æ¦‚è¿°

### 1.1 æ ¸å¿ƒè®¾è®¡åŸåˆ™ï¼ˆJennyå¼ä¿®æ­£ï¼‰
- **æ¶ˆæ¯é¡ºåºæ€§ä¿è¯**ï¼šåŒä¸€ç”¨æˆ·çš„æ¶ˆæ¯å¿…é¡»æŒ‰æ—¶é—´é¡ºåºå¤„ç†ï¼ˆåˆ†åŒºå†…è¿ç»­æäº¤ä¿è¯ï¼‰
- **åˆ†åŒºçº§å¹¶è¡Œå¤„ç†**ï¼šä¸åŒç”¨æˆ·å¹¶è¡Œï¼ŒåŒåˆ†åŒºå†…å®‰å…¨å¹¶å‘+è¿ç»­æäº¤
- **å®¹é”™ä¸é«˜å¯ç”¨**ï¼šæ”¯æŒèŠ‚ç‚¹æ•…éšœè‡ªåŠ¨æ¢å¤ï¼Œ**çœŸæ­£çš„**ä¸ä¸¢æ¶ˆæ¯ï¼ˆéç†è®ºä¸Šçš„ï¼‰
- **æ°´å¹³æ‰©å±•**ï¼šæ”¯æŒåŠ¨æ€å¢å‡èŠ‚ç‚¹ï¼Œ`cooperative-sticky`åˆ†åŒºåˆ†é…
- **å¹³æ»‘è¿‡æ¸¡**ï¼šåŸºäºæ ‡å‡†`confluent-kafka-go`å®ç°ï¼Œé…ç½®å…¼å®¹å•ç‚¹/é›†ç¾¤

### 1.2 Jennyå¼ç®€åŒ–æ¶æ„
```
å¾®ä¿¡å›è°ƒ â†’ kmq.Producer â†’ Kafka Topic(12 Partitions) â†’ kmq.Consumer + PartitionCommitGate
             â†“                        â†“                              â†“
      ç»Ÿä¸€murmur2åˆ†åŒº        æŒ‰UserID Hashåˆ†åŒº           åˆ†åŒºå†…è¿ç»­æäº¤é—¸é—¨
             â†“                        â†“                              â†“
        DLQå…œåº•å¤„ç†              æ¶ˆæ¯ä¸ä¸¢å¤±                  ä¸šåŠ¡å¤„ç†å™¨å¹¶å‘
```

**æ¶æ„ç®€åŒ–è¦ç‚¹**ï¼š
- **ç§»é™¤**ï¼šUserProcessorçŠ¶æ€ç®¡ç†ã€å¤šå±‚ç†”æ–­å™¨ã€å¤æ‚é™çº§é€»è¾‘
- **ä¿ç•™**ï¼šæ ¸å¿ƒä¸šåŠ¡ä»·å€¼ + Kafkaå¯é æ€§ä¿è¯
- **æ ¸å¿ƒ**ï¼š`PartitionCommitGate`è§£å†³è¿ç»­æäº¤ï¼Œå…¶ä»–ä¸€åˆ‡ä»ç®€

---

## 2. Kafka Topic è®¾è®¡

### 2.1 Topic é…ç½®ï¼ˆé…ç½®ä¿®æ­£ç‰ˆï¼‰

#### ç”Ÿäº§ç¯å¢ƒé…ç½®ï¼ˆé›†ç¾¤ï¼‰
```yaml
topic:
  name: qywx-chat-messages
  partitions: 12          # 3èŠ‚ç‚¹ Ã— 4ï¼Œæ”¯æŒæ°´å¹³æ‰©å±•
  replication-factor: 3   # 3å‰¯æœ¬ï¼ŒçœŸæ­£çš„é«˜å¯ç”¨
  min.insync.replicas: 2  # æœ€å°‘åŒæ­¥å‰¯æœ¬æ•°ï¼Œacks=allæ—¶ç”Ÿæ•ˆ
  retention.ms: 604800000 # 7å¤©ä¿ç•™æœŸ
  compression.type: lz4   # å¹³è¡¡å‹ç¼©ç‡å’ŒCPUå¼€é”€
  max.message.bytes: 1048576  # æœ€å¤§æ¶ˆæ¯1MB
```

#### å¼€å‘ç¯å¢ƒé…ç½®ï¼ˆå•ç‚¹ï¼‰
```yaml
# âœ… å•ç‚¹Kafkaçš„æ­£ç¡®é…ç½®
topic:
  name: qywx-chat-messages
  partitions: 4           # å•èŠ‚ç‚¹å»ºè®®1-4ä¸ªåˆ†åŒºï¼Œä¾¿äºå¼€å‘è°ƒè¯•
  replication-factor: 1   # âš ï¸ å¿…é¡»ä¸º1ï¼ˆå•ç‚¹åªæœ‰1ä¸ªbrokerï¼‰
  min.insync.replicas: 1  # âš ï¸ å¿…é¡»ä¸º1ï¼ˆå¦åˆ™acks=allæ— æ³•å·¥ä½œï¼‰
  retention.ms: 604800000 # 7å¤©ä¿ç•™æœŸ
  compression.type: lz4   # å‹ç¼©ç®—æ³•
  max.message.bytes: 1048576  # æœ€å¤§æ¶ˆæ¯1MB

# DLQ Topicï¼ˆä½¿ç”¨ç›¸åŒé…ç½®ä¿è¯ä¸€è‡´æ€§ï¼‰
dlq_topic:
  name: qywx-dead-letter-queue
  partitions: 4           # ä¸ä¸»Topicä¿æŒä¸€è‡´ï¼Œä¾¿äºå›æµ
  replication-factor: 1   # âš ï¸ å¿…é¡»ä¸º1
  min.insync.replicas: 1  # âš ï¸ å¿…é¡»ä¸º1
```

### 2.2 åˆ†åŒºç­–ç•¥ï¼ˆç»Ÿä¸€ä¿®æ­£ï¼‰
- **åˆ†åŒºé”®**ï¼šä½¿ç”¨ `external_user_id` ä½œä¸º Partition Key
- **åˆ†åŒºå™¨**ï¼šç»Ÿä¸€ä½¿ç”¨ `murmur2_random`ï¼ˆä¸Javaå®¢æˆ·ç«¯å¯¹é½ï¼‰
- **åˆ†åŒºåˆ†é…**ï¼š12ä¸ªåˆ†åŒºå‡åŒ€åˆ†é…ç»™æ¶ˆè´¹èŠ‚ç‚¹ï¼Œæ”¯æŒ`cooperative-sticky`åŠ¨æ€rebalance
- **DLQä¸€è‡´æ€§**ï¼šDLQä½¿ç”¨ç›¸åŒçš„åˆ†åŒºå™¨å’Œkeyï¼Œä¿è¯å›æµæ¶ˆæ¯å‘½ä¸­åŸåˆ†åŒº

---

## 3. ç”Ÿäº§è€…è®¾è®¡ï¼ˆåŸºäºkmqåŒ…è£…ï¼‰

### 3.1 Jennyå¼ç®€åŒ–ç”Ÿäº§è€…

**è®¾è®¡æ€è·¯**ï¼šç›´æ¥ä½¿ç”¨é¡¹ç›®ä¸­çš„`kmq.Producer`ï¼Œé¿å…é‡å¤é€ è½®å­ã€‚

```go
package producer

import (
    "encoding/json"
    "time"
    "qywx/infrastructures/mq/kmq"
    "qywx/infrastructures/wxmsg/kefu"
)

// MessageProducer åŸºäºkmqçš„æ¶ˆæ¯ç”Ÿäº§è€…
type MessageProducer struct {
    producer *kmq.Producer
    dlq      *kmq.DLQ
    topic    string
}

// NewMessageProducer åˆ›å»ºç”Ÿäº§è€…å®ä¾‹
func NewMessageProducer(brokers, topic string) (*MessageProducer, error) {
    // ä½¿ç”¨kmq.Producerï¼Œé…ç½®å·²ç»ä¼˜åŒ–ï¼ˆlibrdkafkaæ­£ç¡®é…ç½®é”®ï¼‰
    producer, err := kmq.NewProducer(brokers, "qywx-message-producer")
    if err != nil {
        return nil, fmt.Errorf("create producer failed: %w", err)
    }

    // åˆ›å»ºDLQï¼ˆä½¿ç”¨ç›¸åŒåˆ†åŒºå™¨ï¼‰
    dlq, err := kmq.NewDLQ(brokers, "qywx-message-dlq", "qywx-dead-letter-queue")
    if err != nil {
        producer.Close()
        return nil, fmt.Errorf("create DLQ failed: %w", err)
    }

    return &MessageProducer{
        producer: producer,
        dlq:      dlq,
        topic:    topic,
    }, nil
}

// ProduceMessage å‘é€æ¶ˆæ¯ï¼ˆJennyå¼ç®€åŒ–ç‰ˆï¼‰
func (mp *MessageProducer) ProduceMessage(msg *kefu.KFRecvMessage) error {
    // æ„å»ºæ ‡å‡†æ¶ˆæ¯æ ¼å¼
    chatMsg := &ChatMessage{
        MessageID:      generateMessageID(),
        ExternalUserID: msg.ExternalUserID,
        OpenKFID:       msg.OpenKFID,
        MsgType:        msg.MsgType,
        Content:        msg,
        Timestamp:      time.Now().Unix(),
    }

    value, err := json.Marshal(chatMsg)
    if err != nil {
        return fmt.Errorf("marshal message failed: %w", err)
    }

    headers := []kafka.Header{
        {Key: "msg_type", Value: []byte(msg.MsgType)},
        {Key: "msg_id", Value: []byte(chatMsg.MessageID)},
        {Key: "user_id", Value: []byte(msg.ExternalUserID)},
    }

    // å‘é€åˆ°Kafkaï¼ˆå¼‚æ­¥ï¼‰
    key := []byte(msg.ExternalUserID)  // åˆ†åŒºé”®
    err = mp.producer.Produce(mp.topic, key, value, headers)
    if err != nil {
        // å‘é€å¤±è´¥ï¼Œå°è¯•DLQå…œåº•
        if dlqErr := mp.dlq.Send(key, chatMsg, headers); dlqErr != nil {
            // DLQä¹Ÿå¤±è´¥ï¼Œå°è¯•MySQLå…œåº•ï¼ˆæœ€åçš„ä¿é™©ï¼‰
            // TODO: å®ç°MySQLé™çº§å­˜å‚¨ï¼ˆå½“æ•°æ®åº“å¼•å…¥åå®ç°ï¼‰
            // if mysqlErr := mp.persistToMySQL(chatMsg); mysqlErr != nil {
            //     return fmt.Errorf("all failed: produce=%w, dlq=%w, mysql=%w", err, dlqErr, mysqlErr)
            // }
            // log.Warn("Message persisted to MySQL fallback", "user_id", msg.ExternalUserID)
            // return nil  // MySQLæˆåŠŸï¼Œè¿”å›æˆåŠŸï¼ˆéšè—Kafkaæ•…éšœï¼‰

            return fmt.Errorf("both produce and DLQ failed: produce=%w, dlq=%w", err, dlqErr)
        }
        return fmt.Errorf("produce failed, sent to DLQ: %w", err)
    }

    return nil
}

// Close ä¼˜é›…å…³é—­
func (mp *MessageProducer) Close() {
    mp.producer.Flush(10000)  // ç­‰å¾…10ç§’å‘é€å®Œæˆ
    mp.producer.Close()
    mp.dlq.Close()            // DLQå†…éƒ¨å·²ç»å®ç°äº†Flushé€»è¾‘
}
```


### 3.2 é…ç½®è¯¦è§£ï¼ˆlibrdkafkaæ­£ç¡®é”®åï¼‰

**é‡è¦ä¿®æ­£**ï¼šåŸè®¾è®¡ä½¿ç”¨Javaå®¢æˆ·ç«¯é…ç½®é”®ï¼Œåœ¨`librdkafka`ä¸‹æ— æ•ˆï¼

```go
// kmq/producer.go ä¸­çš„æ­£ç¡®é…ç½®ï¼ˆå·²å®ç°ï¼‰
cfg := &kafka.ConfigMap{
    "bootstrap.servers":          brokers,
    "client.id":                  clientID,

    // å¯é æ€§é…ç½®ï¼ˆä½¿ç”¨librdkafkaæ­£ç¡®é”®åï¼‰
    "acks":                       "all",
    "enable.idempotence":         true,
    "message.send.max.retries":   10,     // âœ… æ­£ç¡®ï¼Œä¸æ˜¯"retries"
    "message.timeout.ms":         30000,  // âœ… æ­£ç¡®ï¼Œä¸æ˜¯"request.timeout.ms"

    // æ‰¹å¤„ç†é…ç½®ï¼ˆlibrdkafkaé”®åï¼‰
    "linger.ms":                  10,
    "batch.num.messages":         1000,   // âœ… æ­£ç¡®ï¼Œä¸æ˜¯"batch.size"
    "queue.buffering.max.ms":     50,
    "queue.buffering.max.kbytes": 102400,

    // å‹ç¼©å’Œè¿æ¥
    "compression.type":           "lz4",
    "socket.keepalive.enable":    true,
    "connections.max.idle.ms":    300000,

    // ä¸»é¢˜çº§é…ç½®ï¼ˆå…³é”®ä¿®æ­£ï¼‰
    "default.topic.config": kafka.ConfigMap{
        "partitioner": "murmur2_random",  // âœ… ä¸Javaå¯¹é½çš„åˆ†åŒºå™¨
    },
}
```

**é…ç½®å¯¹æ¯”è¡¨**ï¼š
| åŠŸèƒ½ | âŒ åŸè®¾è®¡ï¼ˆJavaé”®åï¼‰ | âœ… ä¿®æ­£ç‰ˆï¼ˆlibrdkafkaé”®åï¼‰ |
|------|---------------------|--------------------------|
| é‡è¯•æ¬¡æ•° | `retries: 10` | `message.send.max.retries: 10` |
| æ‰¹é‡å¤§å° | `batch.size: 16384` | `batch.num.messages: 1000` |
| ç¼“å†²æ—¶é—´ | `linger.ms: 10` | `linger.ms: 10` âœ“ |
| è¶…æ—¶è®¾ç½® | `request.timeout.ms` | `message.timeout.ms: 30000` |

### 3.3 é›†æˆåˆ°KFæ¨¡å—ï¼ˆé›¶ç ´åæ€§ä¿®æ”¹ï¼‰

```go
// åœ¨ kf.go ä¸­çš„é›†æˆï¼ˆä¿æŒåŸæœ‰APIï¼‰
func (s *KFService) doHandleEvent(event *kefu.KFCallbackMessage, cm *cursorManager) error {
    // ... å‰é¢çš„åŒæ­¥é€»è¾‘ä¿æŒä¸å˜ ...

    // è·å–æ¶ˆæ¯åï¼Œå‘é€åˆ°Kafkaï¼ˆä¿®æ”¹åçš„ç®€æ´å®ç°ï¼‰
    for _, msg := range resp.MsgList {
        msgCopy := msg

        // Jennyå¼ç®€åŒ–ï¼šç›´æ¥å‘é€ï¼Œå¤±è´¥è‡ªåŠ¨DLQ
        if err := s.messageProducer.ProduceMessage(&msgCopy); err != nil {
            log.GetInstance().Sugar.Error("Message produce failed: ", err)
            // ä¸éœ€è¦å¤æ‚çš„é™çº§é€»è¾‘ï¼Œkmqå·²ç»å¤„ç†äº†DLQå…œåº•
        }
    }

    // ... cursoræ›´æ–°é€»è¾‘ ...
}
```

**ç®€åŒ–è¦ç‚¹**ï¼š
- **ç§»é™¤**ï¼šå¤æ‚çš„é™çº§åˆ°æœ¬åœ°channelé€»è¾‘
- **ç§»é™¤**ï¼šå¤šé‡ç†”æ–­å™¨å’ŒçŠ¶æ€ç®¡ç†
- **ä¿ç•™**ï¼šæ ¸å¿ƒä¸šåŠ¡é€»è¾‘ä¸å˜
- **å¢å¼º**ï¼šå¯é æ€§é€šè¿‡æ­£ç¡®çš„Kafkaé…ç½®ä¿è¯

### 3.4 MySQLå…œåº•æ–¹æ¡ˆè®¾è®¡ï¼ˆTODOï¼šå¾…æ•°æ®åº“å¼•å…¥åå®ç°ï¼‰

**ğŸ›¡ï¸ Jennyå¼å…œåº•è®¾è®¡ï¼šä¸‰çº§é™çº§ä¿æŠ¤**

#### ä¸ºä»€ä¹ˆéœ€è¦MySQLå…œåº•ï¼Ÿ

**ç°å®åœºæ™¯åˆ†æ**ï¼š
```
æ­£å¸¸è·¯å¾„ï¼šProducer â†’ Kafka â†’ Consumer âœ…
é™çº§è·¯å¾„1ï¼šProducer â†’ DLQ â†’ äººå·¥å¤„ç† âš ï¸
é™çº§è·¯å¾„2ï¼šProducer â†’ MySQL â†’ è¡¥å¿ä»»åŠ¡ â†’ Kafka ğŸ›¡ï¸ï¼ˆæœ€åçš„ä¿é™©ï¼‰
```

**æ ¸å¿ƒä»·å€¼**ï¼š
1. **æ¶ˆæ¯æ°¸ä¸ä¸¢å¤±**ï¼šå³ä½¿Kafkaé›†ç¾¤å®Œå…¨æ•…éšœï¼Œæ¶ˆæ¯ä»ç„¶ä¿å­˜åœ¨MySQL
2. **è‡ªåŠ¨æ¢å¤**ï¼šKafkaæ¢å¤åï¼Œè¡¥å¿ä»»åŠ¡è‡ªåŠ¨å›æ”¾MySQLä¸­çš„æ¶ˆæ¯
3. **é¡ºåºæ€§ä¿è¯**ï¼šæŒ‰ç”¨æˆ·åˆ†ç»„ï¼Œä¿è¯åŒç”¨æˆ·æ¶ˆæ¯é¡ºåº

#### æ•°æ®åº“è¡¨ç»“æ„è®¾è®¡ï¼ˆTODOï¼‰

```sql
-- æ¶ˆæ¯é™çº§å­˜å‚¨è¡¨
CREATE TABLE `kafka_fallback_messages` (
    `id` BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
    `message_id` VARCHAR(64) NOT NULL COMMENT 'æ¶ˆæ¯å”¯ä¸€ID',
    `user_id` VARCHAR(128) NOT NULL COMMENT 'ç”¨æˆ·IDï¼ˆåˆ†åŒºé”®ï¼‰',
    `open_kf_id` VARCHAR(128) NOT NULL COMMENT 'å®¢æœè´¦å·',
    `msg_type` VARCHAR(32) NOT NULL COMMENT 'æ¶ˆæ¯ç±»å‹',
    `content` JSON NOT NULL COMMENT 'æ¶ˆæ¯å†…å®¹ï¼ˆJSONæ ¼å¼ï¼‰',
    `status` ENUM('pending', 'retrying', 'success', 'failed') DEFAULT 'pending',
    `retry_count` INT DEFAULT 0 COMMENT 'é‡è¯•æ¬¡æ•°',
    `max_retries` INT DEFAULT 10 COMMENT 'æœ€å¤§é‡è¯•æ¬¡æ•°',
    `error_message` TEXT COMMENT 'æœ€åé”™è¯¯ä¿¡æ¯',
    `created_at` TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    `updated_at` TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    `next_retry_at` TIMESTAMP NULL COMMENT 'ä¸‹æ¬¡é‡è¯•æ—¶é—´',

    PRIMARY KEY (`id`),
    UNIQUE KEY `uk_message_id` (`message_id`),
    KEY `idx_user_id_status` (`user_id`, `status`, `created_at`),
    KEY `idx_next_retry` (`status`, `next_retry_at`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='Kafkaé™çº§æ¶ˆæ¯å­˜å‚¨è¡¨';

-- åˆ†åŒºä¼˜åŒ–ï¼ˆæŒ‰æœˆåˆ†åŒºï¼Œä¾¿äºå½’æ¡£ï¼‰
ALTER TABLE `kafka_fallback_messages`
PARTITION BY RANGE (UNIX_TIMESTAMP(`created_at`)) (
    PARTITION p202501 VALUES LESS THAN (UNIX_TIMESTAMP('2025-02-01')),
    PARTITION p202502 VALUES LESS THAN (UNIX_TIMESTAMP('2025-03-01')),
    -- ... æ›´å¤šåˆ†åŒº
);
```

#### å®ç°ç­–ç•¥ï¼ˆTODOï¼‰

```go
// persistToMySQL å°†æ¶ˆæ¯æŒä¹…åŒ–åˆ°MySQLï¼ˆæœ€åçš„å…œåº•ï¼‰
func (mp *MessageProducer) persistToMySQL(msg *ChatMessage) error {
    // TODO: å®ç°MySQLæŒä¹…åŒ–é€»è¾‘
    // 1. è·å–æ•°æ®åº“è¿æ¥ï¼ˆä½¿ç”¨è¿æ¥æ± ï¼‰
    // 2. æ’å…¥æ¶ˆæ¯åˆ°kafka_fallback_messagesè¡¨
    // 3. è®°å½•ç›‘æ§æŒ‡æ ‡
    // 4. è¿”å›æˆåŠŸ/å¤±è´¥

    // ä¼ªä»£ç ç¤ºä¾‹ï¼š
    /*
    query := `
        INSERT INTO kafka_fallback_messages
        (message_id, user_id, open_kf_id, msg_type, content, status, next_retry_at)
        VALUES (?, ?, ?, ?, ?, 'pending', DATE_ADD(NOW(), INTERVAL 1 MINUTE))
    `

    _, err := db.Exec(query,
        msg.MessageID,
        msg.ExternalUserID,
        msg.OpenKFID,
        msg.MsgType,
        jsonContent,
    )

    if err != nil {
        return fmt.Errorf("persist to MySQL failed: %w", err)
    }

    mp.metrics.MySQLFallbacks.Inc()
    return nil
    */

    return fmt.Errorf("MySQL persistence not yet implemented")
}
```

#### è¡¥å¿ä»»åŠ¡è®¾è®¡ï¼ˆTODOï¼‰

```go
// MessageCompensator æ¶ˆæ¯è¡¥å¿å™¨ï¼ˆç‹¬ç«‹æœåŠ¡/åç¨‹ï¼‰
type MessageCompensator struct {
    db       *sql.DB
    producer *kmq.Producer
    interval time.Duration
}

// Start å¯åŠ¨è¡¥å¿ä»»åŠ¡
func (mc *MessageCompensator) Start(ctx context.Context) {
    ticker := time.NewTicker(mc.interval)
    defer ticker.Stop()

    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            mc.compensatePendingMessages()
        }
    }
}

// compensatePendingMessages è¡¥å¿å¾…å‘é€æ¶ˆæ¯
func (mc *MessageCompensator) compensatePendingMessages() {
    // TODO: å®ç°è¡¥å¿é€»è¾‘
    // 1. æŸ¥è¯¢status='pending'æˆ–'retrying'ä¸”next_retry_at <= NOW()çš„æ¶ˆæ¯
    // 2. æŒ‰user_idåˆ†ç»„ï¼Œä¿è¯åŒç”¨æˆ·æ¶ˆæ¯é¡ºåº
    // 3. å°è¯•å‘é€åˆ°Kafka
    // 4. æˆåŠŸï¼šæ›´æ–°status='success'
    // 5. å¤±è´¥ï¼šæ›´æ–°retry_countå’Œnext_retry_atï¼ˆæŒ‡æ•°é€€é¿ï¼‰
    // 6. è¶…è¿‡max_retriesï¼šæ ‡è®°ä¸º'failed'ï¼Œäººå·¥ä»‹å…¥
}
```

#### ç›‘æ§æŒ‡æ ‡ï¼ˆTODOï¼‰

```go
type MySQLFallbackMetrics struct {
    MessagesStored     counter   // å­˜å‚¨åˆ°MySQLçš„æ¶ˆæ¯æ•°
    CompensateSuccess  counter   // è¡¥å¿æˆåŠŸæ•°
    CompensateFailed   counter   // è¡¥å¿å¤±è´¥æ•°
    PendingMessages    gauge     // å¾…è¡¥å¿æ¶ˆæ¯æ•°
    OldestPendingAge   gauge     // æœ€è€å¾…è¡¥å¿æ¶ˆæ¯å¹´é¾„ï¼ˆç§’ï¼‰
}

// å‘Šè­¦è§„åˆ™
alerts:
  - name: MySQLFallbackActive
    condition: mysql_fallback_rate > 0
    duration: 1m
    severity: warning
    message: "Kafkaæ•…éšœï¼Œæ¶ˆæ¯é™çº§åˆ°MySQL"

  - name: CompensationBacklog
    condition: pending_messages > 1000
    duration: 5m
    severity: critical
    message: "MySQLè¡¥å¿ç§¯å‹è¿‡å¤šï¼Œæ£€æŸ¥KafkaçŠ¶æ€"
```

#### Jennyæ¶æ„æ€ç»´ä½“ç°

**æ•°æ®ç»“æ„ä¼˜å…ˆ**ï¼š
- è®¾è®¡åˆç†çš„è¡¨ç»“æ„ï¼Œæ”¯æŒé«˜æ•ˆæŸ¥è¯¢å’Œè¡¥å¿
- æŒ‰ç”¨æˆ·åˆ†ç»„ä¿è¯é¡ºåºæ€§

**æ¶ˆé™¤ç‰¹æ®Šæƒ…å†µ**ï¼š
- ç»Ÿä¸€çš„é™çº§é“¾ï¼šKafka â†’ DLQ â†’ MySQL
- æ¯ä¸€çº§éƒ½æ˜¯æ ‡å‡†çš„å¤„ç†æµç¨‹ï¼Œæ²¡æœ‰ç‰¹æ®Šåˆ†æ”¯

**å®ç”¨ä¸»ä¹‰**ï¼š
- å½“å‰æ ‡è®°ä¸ºTODOï¼Œä¸è¿‡åº¦è®¾è®¡
- ç­‰æ•°æ®åº“çœŸæ­£å¼•å…¥åå†å®ç°
- ä¿æŒæ¶æ„çš„æ‰©å±•æ€§

**é›¶ç ´åæ€§**ï¼š
- MySQLé™çº§å¯¹ä¸Šå±‚é€æ˜
- è¡¥å¿ä»»åŠ¡è‡ªåŠ¨æ¢å¤ï¼Œä¸éœ€è¦äººå·¥å¹²é¢„
- ä¿æŒæ¶ˆæ¯çš„æœ€ç»ˆä¸€è‡´æ€§

---

## 4. æ¶ˆè´¹è€…è®¾è®¡ï¼ˆPartitionCommitGateæ ¸å¿ƒï¼‰

### 4.1 Jennyå¼æ¶ˆè´¹è€…æ¶æ„

**è®¾è®¡æ ¸å¿ƒ**ï¼šä½¿ç”¨`kmq.Consumer`çš„`PartitionCommitGate`æœºåˆ¶è§£å†³åŸè®¾è®¡çš„è‡´å‘½é—®é¢˜ã€‚

```go
package consumer

import (
    "context"
    "encoding/json"
    "time"
    "qywx/infrastructures/mq/kmq"
    "github.com/confluentinc/confluent-kafka-go/v2/kafka"
)

// MessageConsumer åŸºäºkmqçš„æ¶ˆæ¯æ¶ˆè´¹è€…
type MessageConsumer struct {
    consumer  *kmq.Consumer
    dlq       *kmq.DLQ
    processor MessageProcessor
    ctx       context.Context
    cancel    context.CancelFunc
}

// MessageProcessor ä¸šåŠ¡å¤„ç†æ¥å£
type MessageProcessor interface {
    ProcessMessage(msg *ChatMessage) error
    GetUserID() string  // ç”¨äºè·¯ç”±å’Œç›‘æ§
}

// NewMessageConsumer åˆ›å»ºæ¶ˆè´¹è€…
func NewMessageConsumer(brokers, groupID string, processor MessageProcessor) (*MessageConsumer, error) {
    // ä½¿ç”¨kmq.Consumerï¼ˆå·²é…ç½®cooperative-sticky + æ‰‹åŠ¨æäº¤ï¼‰
    consumer, err := kmq.NewConsumer(brokers, groupID)
    if err != nil {
        return nil, fmt.Errorf("create consumer failed: %w", err)
    }

    // DLQï¼ˆç»Ÿä¸€åˆ†åŒºå™¨ï¼‰
    dlq, err := kmq.NewDLQ(brokers, "qywx-consumer-dlq", "qywx-dead-letter-queue")
    if err != nil {
        consumer.Close()
        return nil, fmt.Errorf("create DLQ failed: %w", err)
    }

    ctx, cancel := context.WithCancel(context.Background())

    return &MessageConsumer{
        consumer:  consumer,
        dlq:       dlq,
        processor: processor,
        ctx:       ctx,
        cancel:    cancel,
    }, nil
}

// Start å¯åŠ¨æ¶ˆè´¹ï¼ˆå®ç°kmq.MessageHandleræ¥å£ï¼‰
func (mc *MessageConsumer) Start(topics []string) error {
    if err := mc.consumer.Subscribe(topics); err != nil {
        return fmt.Errorf("subscribe failed: %w", err)
    }

    // æ ¸å¿ƒï¼šå®ç°kmq.MessageHandleræ¥å£
    handler := func(m *kafka.Message) (handled bool, err error) {
        return mc.handleMessage(m)
    }

    // ä½¿ç”¨kmqçš„PollAndDispatchï¼ˆåŒ…å«PartitionCommitGateé€»è¾‘ï¼‰
    go mc.consumer.PollAndDispatch(handler, 100)
    return nil
}

// handleMessage å®ç°ä¸šåŠ¡å¤„ç†é€»è¾‘
func (mc *MessageConsumer) handleMessage(m *kafka.Message) (handled bool, err error) {
    // è§£ææ¶ˆæ¯
    var chatMsg ChatMessage
    if err := json.Unmarshal(m.Value, &chatMsg); err != nil {
        // è§£æå¤±è´¥ï¼Œå‘é€åˆ°DLQ
        if dlqErr := mc.dlq.Send(m.Key, m.Value, m.Headers); dlqErr != nil {
            return false, fmt.Errorf("both unmarshal and DLQ failed: %w", dlqErr)
        }
        return true, nil  // DLQæˆåŠŸ = handled
    }

    // ä¸šåŠ¡å¤„ç†
    if err := mc.processor.ProcessMessage(&chatMsg); err != nil {
        // ä¸šåŠ¡å¤±è´¥ï¼Œå‘é€åˆ°DLQ
        if dlqErr := mc.dlq.Send(m.Key, chatMsg, m.Headers); dlqErr != nil {
            return false, fmt.Errorf("both process and DLQ failed: %w", dlqErr)
        }
        return true, nil  // DLQæˆåŠŸ = handled
    }

    return true, nil  // å¤„ç†æˆåŠŸ = handled
}

// Stop ä¼˜é›…åœæœº
func (mc *MessageConsumer) Stop() {
    mc.cancel()
    mc.consumer.Close()
    mc.dlq.Close()
}
```

### 4.2 PartitionCommitGateåŸç†ï¼ˆè§£å†³è‡´å‘½é—®é¢˜ï¼‰

**åŸè®¾è®¡çš„è‡´å‘½é”™è¯¯**ï¼š
```go
// âŒ é”™è¯¯çš„æäº¤æ–¹å¼ï¼ˆä¼šä¸¢æ¶ˆæ¯ï¼‰
consumer.CommitMessage(msg)  // æ¯æ¡æ¶ˆæ¯æˆåŠŸåç«‹å³æäº¤
```

**é—®é¢˜åˆ†æ**ï¼šåŒä¸€åˆ†åŒºå†…ï¼Œå¦‚æœoffset=10çš„æ¶ˆæ¯å…ˆå®Œæˆå¹¶æäº¤ï¼Œoffset=8çš„æ¶ˆæ¯è¿˜åœ¨å¤„ç†ä¸­ï¼Œé‚£ä¹ˆé‡å¯åä¼šä»offset=11å¼€å§‹æ¶ˆè´¹ï¼Œoffset=8å’Œ9æ°¸è¿œä¸¢å¤±ï¼

**PartitionCommitGateè§£å†³æ–¹æ¡ˆ**ï¼š
```go
// kmq/commit_gate.go çš„æ ¸å¿ƒé€»è¾‘
type PartitionCommitGate struct {
    nextCommit int64                // ä¸‹ä¸€ä¸ªè¦æäº¤çš„è¿ç»­offset
    done       map[int64]struct{}  // å·²å®Œæˆçš„offsetï¼ˆæˆåŠŸæˆ–DLQï¼‰
}

// åªæœ‰è¿ç»­å®Œæˆæ‰æ¨è¿›æäº¤
func (g *PartitionCommitGate) tryAdvance() int64 {
    advanced := int64(-1)
    for {
        if _, ok := g.done[g.nextCommit]; ok {  // æ£€æŸ¥è¿ç»­æ€§
            delete(g.done, g.nextCommit)
            advanced = g.nextCommit
            g.nextCommit++  // æ¨è¿›è¿ç»­æŒ‡é’ˆ
            continue
        }
        break  // ä¸è¿ç»­ï¼Œåœæ­¢æ¨è¿›
    }
    return advanced
}
```

**ä¸¾ä¾‹è¯´æ˜**ï¼š
```
åˆ†åŒºæ¶ˆæ¯: [8, 9, 10, 11, 12]
å¤„ç†å®Œæˆé¡ºåº: 10âœ… â†’ 8âœ… â†’ 12âœ… â†’ 9âœ… â†’ 11âœ…

PartitionCommitGateè¡Œä¸º:
1. 10å®Œæˆ â†’ done={10}, nextCommit=8, ä¸æ¨è¿›ï¼ˆ8æœªå®Œæˆï¼‰
2. 8å®Œæˆ  â†’ done={8,10}, nextCommit=8, æ£€æŸ¥è¿ç»­æ€§:
   - 8å®Œæˆâœ… â†’ nextCommit=9, advanced=8
   - 9æœªå®ŒæˆâŒ â†’ åœæ­¢ï¼Œæäº¤åˆ°offset=9
3. 12å®Œæˆ â†’ done={9,10,12}, ä¸æ¨è¿›ï¼ˆ9æœªå®Œæˆï¼‰
4. 9å®Œæˆ  â†’ done={9,10,12}, nextCommit=9, æ£€æŸ¥è¿ç»­æ€§:
   - 9å®Œæˆâœ… â†’ nextCommit=10, advanced=9
   - 10å®Œæˆâœ… â†’ nextCommit=11, advanced=10
   - 11æœªå®ŒæˆâŒ â†’ åœæ­¢ï¼Œæäº¤åˆ°offset=11
5. 11å®Œæˆ â†’ æœ€ç»ˆæäº¤åˆ°offset=13

ç»“æœï¼šæ²¡æœ‰æ¶ˆæ¯ä¸¢å¤±ï¼Œä¿è¯è¿ç»­æ€§ï¼
```

### 4.3 æ¶ˆè´¹è€…é…ç½®ï¼ˆcooperative-stickyï¼‰

```go
// kmq/consumer.go ä¸­çš„é…ç½®ï¼ˆå·²å®ç°ï¼‰
cfg := &kafka.ConfigMap{
    "bootstrap.servers":               brokers,
    "group.id":                        groupID,

    // åˆ†åŒºåˆ†é…ç­–ç•¥ï¼ˆæ”¯æŒå¢é‡rebalanceï¼‰
    "partition.assignment.strategy":    "cooperative-sticky",

    // æ‰‹åŠ¨æäº¤é…ç½®ï¼ˆé…åˆPartitionCommitGateï¼‰
    "enable.auto.commit":               false,
    "enable.auto.offset.store":         false,

    // ä¼šè¯ç®¡ç†
    "session.timeout.ms":               30000,
    "heartbeat.interval.ms":            3000,
    "max.poll.interval.ms":             300000,

    // æ‹‰å–é…ç½®
    "fetch.min.bytes":                  1024,
    "fetch.wait.max.ms":                500,

    // ç§»é™¤æ— æ„ä¹‰çš„é…ç½®
    // "isolation.level": "read_committed",  // âŒ æœªå¯ç”¨äº‹åŠ¡æ—¶æ— æ•ˆ
}
```

### 4.4 Rebalanceå®‰å…¨å¤„ç†

```go
// kmq/consumer.go ä¸­çš„rebalanceå›è°ƒï¼ˆå·²å®ç°ï¼‰
err := c.SubscribeTopics(topics, func(c *kafka.Consumer, e kafka.Event) error {
    switch ev := e.(type) {
    case kafka.AssignedPartitions:
        // å¢é‡åˆ†é…ï¼šä¸ºæ–°åˆ†åŒºåˆ›å»ºPartitionCommitGate
        cc.gatesM.Lock()
        for _, tp := range ev.Partitions {
            start := int64(tp.Offset)
            if start < 0 { start = 0 }
            cc.gates[tp.Partition] = NewPartitionCommitGate(*tp.Topic, tp.Partition, start)
        }
        cc.gatesM.Unlock()
        return c.IncrementalAssign(ev.Partitions)

    case kafka.RevokedPartitions:
        // å¢é‡æ’¤é”€ï¼šå®‰å…¨å†²åˆ·åˆ†åŒºæäº¤
        cc.gatesM.Lock()
        for _, tp := range ev.Partitions {
            if g, ok := cc.gates[tp.Partition]; ok {
                _ = g.CommitContiguous(c)  // å°½åŠ›æ¨è¿›æœ€ç»ˆæäº¤
                delete(cc.gates, tp.Partition)
            }
        }
        cc.gatesM.Unlock()
        return c.IncrementalUnassign(ev.Partitions)
    }
    return nil
})
```

**Rebalanceå®‰å…¨è¦ç‚¹**ï¼š
- **cooperative-sticky**ï¼šå‡å°‘åˆ†åŒºç§»åŠ¨ï¼Œæ”¯æŒå¢é‡åˆ†é…
- **æ’¤é”€å‰å†²åˆ·**ï¼šç¡®ä¿åˆ†åŒºå†…æ‰€æœ‰å¯æäº¤çš„offsetéƒ½è¢«æäº¤
- **çŠ¶æ€æ¸…ç†**ï¼šæ¸…ç†æ’¤é”€åˆ†åŒºçš„PartitionCommitGateï¼Œé¿å…å†…å­˜æ³„æ¼

---

## 5. DLQè®¾è®¡ï¼ˆæç®€åŒ–ç‰ˆæœ¬ï¼‰

### 5.1 Jennyå¼DLQç®€åŒ–

**åŸè®¾è®¡é—®é¢˜**ï¼šDLQè®¾è®¡è¿‡äºå¤æ‚ï¼ŒåŒ…å«æ¢å¤ç­–ç•¥ã€ä¼˜å…ˆçº§ã€TTLç­‰ç†è®ºæ¦‚å¿µï¼Œå®é™…è¿ç»´ä¸­éš¾ä»¥æ‰§è¡Œã€‚

**Jennyå¼ç®€åŒ–åŸåˆ™**ï¼šDLQå°±æ˜¯æ­»ä¿¡é˜Ÿåˆ—ï¼Œä¿å­˜å¤±è´¥æ¶ˆæ¯ä¾›åç»­åˆ†æå³å¯ï¼Œä¸è¦è¿‡åº¦è®¾è®¡ï¼

```go
// ä½¿ç”¨kmq.DLQï¼ˆå·²å®ç°æç®€ç‰ˆæœ¬ï¼‰
type DLQ struct {
    p     *Producer  // ä½¿ç”¨ç›¸åŒçš„åˆ†åŒºå™¨é…ç½®
    topic string
}

// Send å‘é€åˆ°æ­»ä¿¡é˜Ÿåˆ—ï¼ˆç»Ÿä¸€æ¥å£ï¼‰
func (d *DLQ) Send(key []byte, v interface{}, headers []kafka.Header) error {
    // æ„å»ºç®€å•çš„DLQæ¶ˆæ¯
    dlqMsg := map[string]interface{}{
        "original_message": v,
        "failed_at":        time.Now().Unix(),
        "error_context":    "processing_failed",
    }

    // æ·»åŠ DLQç‰¹æœ‰header
    dlqHeaders := append(headers,
        kafka.Header{Key: "dlq_timestamp", Value: []byte(fmt.Sprintf("%d", time.Now().Unix()))},
        kafka.Header{Key: "dlq_source", Value: []byte("qywx-consumer")},
    )

    b, err := json.Marshal(dlqMsg)
    if err != nil {
        return fmt.Errorf("marshal DLQ message: %w", err)
    }

    // ä½¿ç”¨ç›¸åŒåˆ†åŒºå™¨å‘é€ï¼ˆä¿è¯ä¸€è‡´æ€§ï¼‰
    return d.p.Produce(d.topic, key, b, dlqHeaders)
}
```

### 5.2 DLQ Topicé…ç½®

```yaml
# DLQ Topicé…ç½®ï¼ˆç®€åŒ–ç‰ˆï¼‰
dlq_topic:
  name: qywx-dead-letter-queue
  partitions: 12          # ä¸ä¸»Topicç›¸åŒï¼Œä¾¿äºè¿ç»´
  replication-factor: 3   # é«˜å¯ç”¨ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
  min.insync.replicas: 2
  retention.ms: 2592000000  # 30å¤©ä¿ç•™ï¼ˆæ›´é•¿æ—¶é—´ç”¨äºåˆ†æï¼‰
  compression.type: snappy  # æ›´é«˜å‹ç¼©æ¯”ï¼ˆDLQæ¶ˆæ¯é€šå¸¸è¾ƒå°‘ï¼‰
```

### 5.3 DLQç›‘æ§ä¸åˆ†æ

```go
// DLQç®€å•ç›‘æ§ï¼ˆå®ç”¨ä¸»ä¹‰æ–¹æ¡ˆï¼‰
type DLQMetrics struct {
    MessagesProduced counter    // DLQæ¶ˆæ¯æ•°é‡
    MessagesByReason map[string]counter  // æŒ‰å¤±è´¥åŸå› åˆ†ç±»
    LastDLQTime      time.Time  // æœ€åä¸€æ¬¡DLQæ—¶é—´
}

// ç›‘æ§å»ºè®®ï¼ˆè¿ç»´è§†è§’ï¼‰
alerts:
  - name: DLQMessageRate
    condition: dlq_messages_5min > 10
    action: warn
    message: "High DLQ rate, check processing logic"

  - name: DLQUserConcentration
    condition: single_user_dlq_ratio > 0.5
    action: warn
    message: "Single user generating most DLQ messages"
```

**DLQå¤„ç†ç­–ç•¥ï¼ˆå®ç”¨ç‰ˆæœ¬ï¼‰**ï¼š
1. **å®æ—¶ç›‘æ§**ï¼šDLQæ¶ˆæ¯ç‡ã€ç”¨æˆ·åˆ†å¸ƒã€å¤±è´¥åŸå› 
2. **å®šæœŸåˆ†æ**ï¼šå‘¨æŠ¥åˆ†æDLQæ¶ˆæ¯æ¨¡å¼ï¼Œæ”¹è¿›å¤„ç†é€»è¾‘
3. **æ‰‹åŠ¨å›æ”¾**ï¼šé‡è¦æ¶ˆæ¯å¯ä»¥æ‰‹åŠ¨ä»DLQå›æ”¾åˆ°ä¸»Topic
4. **å½’æ¡£æ¸…ç†**ï¼šè¶…è¿‡30å¤©çš„DLQæ¶ˆæ¯å½’æ¡£åˆ°å¯¹è±¡å­˜å‚¨

**ä¸åšçš„äº‹æƒ…**ï¼š
- âŒ è‡ªåŠ¨é‡è¯•æœºåˆ¶ï¼ˆå¢åŠ å¤æ‚åº¦ï¼Œæ•ˆæœæœ‰é™ï¼‰
- âŒ å¤æ‚çš„æ¢å¤ç­–ç•¥ï¼ˆç†è®ºå®Œç¾ï¼Œå®è·µå¤æ‚ï¼‰
- âŒ ä¼˜å…ˆçº§ç³»ç»Ÿï¼ˆYAGNI - You Ain't Gonna Need Itï¼‰

---

## 6. é›†æˆä¸éƒ¨ç½²

### 6.1 ä»£ç é›†æˆï¼ˆé›¶ç ´åæ€§ï¼‰

```go
// æ–°çš„KafkaæœåŠ¡åˆå§‹åŒ–
type KafkaService struct {
    producer *MessageProducer
    consumer *MessageConsumer
    dlq      *kmq.DLQ
}

func NewKafkaService(brokers string) (*KafkaService, error) {
    // ç”Ÿäº§è€…
    producer, err := NewMessageProducer(brokers, "qywx-chat-messages")
    if err != nil {
        return nil, fmt.Errorf("create producer: %w", err)
    }

    // æ¶ˆè´¹è€…ï¼ˆæ³¨å…¥ä¸šåŠ¡å¤„ç†å™¨ï¼‰
    processor := &ScheduleMessageProcessor{
        scheduleService: scheduleService,  // æ³¨å…¥ç°æœ‰ä¸šåŠ¡é€»è¾‘
    }
    consumer, err := NewMessageConsumer(brokers, "qywx-consumers", processor)
    if err != nil {
        producer.Close()
        return nil, fmt.Errorf("create consumer: %w", err)
    }

    return &KafkaService{
        producer: producer,
        consumer: consumer,
    }, nil
}

// ä¸šåŠ¡å¤„ç†å™¨å®ç°ï¼ˆé€‚é…ç°æœ‰ä»£ç ï¼‰
type ScheduleMessageProcessor struct {
    scheduleService *ScheduleService
}

func (smp *ScheduleMessageProcessor) ProcessMessage(msg *ChatMessage) error {
    // è½¬æ¢ä¸ºç°æœ‰çš„æ•°æ®ç»“æ„
    kfMsg := &kefu.KFRecvMessage{
        ExternalUserID: msg.ExternalUserID,
        OpenKFID:       msg.OpenKFID,
        MsgType:        msg.MsgType,
        // ... å…¶ä»–å­—æ®µæ˜ å°„
    }

    // è°ƒç”¨ç°æœ‰çš„ä¸šåŠ¡é€»è¾‘ï¼ˆæ— éœ€ä¿®æ”¹ï¼‰
    return smp.scheduleService.ProcessKFMessage(kfMsg)
}
```

### 6.2 é…ç½®ç®¡ç†ï¼ˆç¯å¢ƒç»Ÿä¸€ï¼‰

```yaml
# config/kafka.yamlï¼ˆç»Ÿä¸€é…ç½®ï¼‰
kafka:
  brokers: "${KAFKA_BROKERS:localhost:9092}"

  topics:
    main: "qywx-chat-messages"
    dlq: "qywx-dead-letter-queue"

  producer:
    client_id: "qywx-producer-${HOSTNAME}"
    # kmqå·²åŒ…å«æ‰€æœ‰å¿…éœ€é…ç½®ï¼Œæ— éœ€é‡å¤

  consumer:
    group_id: "qywx-consumers"
    # kmqå·²åŒ…å«æ‰€æœ‰å¿…éœ€é…ç½®ï¼Œæ— éœ€é‡å¤

  # ç¯å¢ƒç‰¹å®šé…ç½®
  development:
    partitions: 4
    replication_factor: 1
    min_insync_replicas: 1

  production:
    partitions: 12
    replication_factor: 3
    min_insync_replicas: 2
```

### 6.3 è¿ç§»ç­–ç•¥ï¼ˆå¹³æ»‘å‡çº§ï¼‰

**Phase 1ï¼šåŒå†™éªŒè¯ï¼ˆ0é£é™©ï¼‰**
```go
// åœ¨ç°æœ‰ä»£ç ä¸­æ·»åŠ åŒå†™é€»è¾‘
func (s *ScheduleService) ProcessMessage(msg *kefu.KFRecvMessage) error {
    // 1. ä¿æŒç°æœ‰å¤„ç†é€»è¾‘ä¸å˜
    err := s.processMessageOriginal(msg)

    // 2. åŒæ­¥å‘é€åˆ°Kafkaï¼ˆéªŒè¯ï¼‰
    go func() {
        if kafkaErr := s.kafkaProducer.ProduceMessage(msg); kafkaErr != nil {
            log.Warn("KafkaåŒå†™å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰:", kafkaErr)
        }
    }()

    return err
}
```

**Phase 2ï¼šæ¶ˆè´¹éªŒè¯ï¼ˆä½é£é™©ï¼‰**
```go
// å¯åŠ¨Kafkaæ¶ˆè´¹è€…ï¼Œä½†åªåšæ—¥å¿—è®°å½•ï¼Œä¸æ‰§è¡Œä¸šåŠ¡é€»è¾‘
func (consumer *MessageConsumer) handleMessage(m *kafka.Message) (handled bool, err error) {
    var chatMsg ChatMessage
    json.Unmarshal(m.Value, &chatMsg)

    // åªè®°å½•æ—¥å¿—ï¼ŒéªŒè¯æ¶ˆè´¹æ­£å¸¸
    log.Info("Kafkaæ¶ˆæ¯éªŒè¯:",
        "user_id", chatMsg.ExternalUserID,
        "msg_type", chatMsg.MsgType,
        "offset", m.TopicPartition.Offset)

    return true, nil  // ç›´æ¥æ ‡è®°ä¸ºhandled
}
```

**Phase 3ï¼šå®Œå…¨åˆ‡æ¢ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰**
```go
// å…³é—­åŸæœ‰å¤„ç†ï¼Œå®Œå…¨åˆ‡æ¢åˆ°Kafkaæ¶ˆè´¹
func (s *ScheduleService) switchToKafkaMode() {
    s.stopOriginalConsumer()    // åœæ­¢åŸæœ‰æ¶ˆè´¹
    s.startKafkaConsumer()      // å¯åŠ¨Kafkaæ¶ˆè´¹
    s.enableKafkaProducer()     // å¯ç”¨Kafkaç”Ÿäº§
}
```

---

## 7. ç›‘æ§ä¸è¿ç»´

### 7.1 å…³é”®æŒ‡æ ‡

**ç”Ÿäº§è€…ç›‘æ§**ï¼š
```go
type ProducerMetrics struct {
    MessagesProduced   counter   // ç”Ÿäº§æ¶ˆæ¯æ•°é‡
    ProduceLatency     histogram // ç”Ÿäº§å»¶è¿Ÿ
    ProduceErrors      counter   // ç”Ÿäº§é”™è¯¯æ•°
    DLQFallbacks      counter   // DLQå…œåº•æ¬¡æ•°
}
```

**æ¶ˆè´¹è€…ç›‘æ§ï¼ˆæ ¸å¿ƒï¼‰**ï¼š
```go
type ConsumerMetrics struct {
    MessagesConsumed   counter   // æ¶ˆè´¹æ¶ˆæ¯æ•°é‡
    ProcessLatency     histogram // å¤„ç†å»¶è¿Ÿ
    ProcessErrors      counter   // å¤„ç†é”™è¯¯æ•°
    CommitGateBacklog  gauge    // é—¸é—¨ç§¯å‹ï¼ˆå…³é”®æŒ‡æ ‡ï¼‰
    RebalanceCount     counter   // Rebalanceæ¬¡æ•°
}

// CommitGateBacklogè®¡ç®—
func (g *PartitionCommitGate) GetBacklog() int64 {
    g.mu.Lock()
    defer g.mu.Unlock()
    return int64(len(g.done))  // å·²å®Œæˆä½†æœªæäº¤çš„æ¶ˆæ¯æ•°
}
```

**å‘Šè­¦è§„åˆ™**ï¼š
```yaml
alerts:
  # å…³é”®å‘Šè­¦ï¼šæäº¤é—¸é—¨ç§¯å‹
  - name: CommitGateBacklog
    condition: max(commit_gate_backlog) > 1000
    duration: 5m
    severity: critical
    message: "PartitionCommitGateç§¯å‹è¿‡å¤šï¼Œå¯èƒ½æœ‰æ¶ˆæ¯å¤„ç†å¡ä½"

  # å…³é”®å‘Šè­¦ï¼šDLQå…œåº•ç‡è¿‡é«˜
  - name: DLQFallbackRate
    condition: rate(dlq_fallbacks_5m) > 0.1
    duration: 2m
    severity: warning
    message: "DLQå…œåº•ç‡è¿‡é«˜ï¼ŒKafkaå¯èƒ½æœ‰é—®é¢˜"

  # Rebalanceé¢‘ç‡å¼‚å¸¸
  - name: RebalanceFrequency
    condition: rate(rebalance_count_1h) > 10
    duration: 1h
    severity: warning
    message: "Rebalanceè¿‡äºé¢‘ç¹ï¼Œæ£€æŸ¥ç½‘ç»œå’Œé…ç½®"
```

### 7.2 è¿ç»´å·¥å…·

```bash
# Kafkaå¥åº·æ£€æŸ¥è„šæœ¬
#!/bin/bash
# kafka-health-check.sh

echo "=== Kafkaé›†ç¾¤çŠ¶æ€ ==="
kafka-topics --bootstrap-server $BROKERS --list

echo "=== Topicåˆ†åŒºçŠ¶æ€ ==="
kafka-topics --bootstrap-server $BROKERS --describe --topic qywx-chat-messages

echo "=== æ¶ˆè´¹ç»„çŠ¶æ€ ==="
kafka-consumer-groups --bootstrap-server $BROKERS --describe --group qywx-consumers

echo "=== ç§¯å‹æƒ…å†µ ==="
kafka-consumer-groups --bootstrap-server $BROKERS --describe --group qywx-consumers | awk '{print $1, $5, $6}' | column -t
```

### 7.3 æ•…éšœå¤„ç†æ‰‹å†Œ

**åœºæ™¯1ï¼šPartitionCommitGateç§¯å‹**
```bash
# 1. æŸ¥çœ‹ç§¯å‹åˆ†åŒº
curl -s localhost:9090/metrics | grep commit_gate_backlog

# 2. æŸ¥çœ‹å¡ä½çš„æ¶ˆæ¯
kafka-console-consumer --bootstrap-server $BROKERS \
  --topic qywx-chat-messages \
  --partition $PARTITION \
  --offset $STUCK_OFFSET \
  --max-messages 10

# 3. æ‰‹åŠ¨è·³è¿‡ï¼ˆç´§æ€¥æƒ…å†µï¼‰
# æ³¨æ„ï¼šè¿™ä¼šä¸¢å¤±å¡ä½çš„æ¶ˆæ¯ï¼Œä»…ç´§æ€¥æ—¶ä½¿ç”¨
kafka-consumer-groups --bootstrap-server $BROKERS \
  --group qywx-consumers \
  --reset-offsets \
  --to-offset $NEW_OFFSET \
  --topic qywx-chat-messages:$PARTITION \
  --execute
```

**åœºæ™¯2ï¼šDLQæ¶ˆæ¯å›æ”¾**
```bash
# 1. æŸ¥çœ‹DLQæ¶ˆæ¯
kafka-console-consumer --bootstrap-server $BROKERS \
  --topic qywx-dead-letter-queue \
  --from-beginning \
  --max-messages 100

# 2. é€‰æ‹©æ€§å›æ”¾åˆ°ä¸»Topic
# ï¼ˆéœ€è¦å¼€å‘ä¸“ç”¨å·¥å…·ï¼Œè¿‡æ»¤å’Œè½¬æ¢DLQæ¶ˆæ¯ï¼‰
./dlq-replay-tool --user-id "specific_user" --time-range "2024-01-01,2024-01-02"
```

---

## 8. æ€§èƒ½æµ‹è¯•ä¸éªŒè¯

### 8.1 æ€§èƒ½åŸºå‡†

**ç”Ÿäº§è€…æ€§èƒ½**ï¼š
```bash
# ä½¿ç”¨kafka-producer-perf-testæµ‹è¯•
kafka-producer-perf-test \
  --topic qywx-chat-messages \
  --num-records 100000 \
  --record-size 1024 \
  --throughput 5000 \
  --producer-props bootstrap.servers=$BROKERS \
                    compression.type=lz4 \
                    batch.num.messages=1000

# æœŸæœ›ç»“æœï¼š
# - ååé‡ï¼š5000+ msgs/sec
# - å»¶è¿ŸP99ï¼š< 50ms
# - CPUä½¿ç”¨ç‡ï¼š< 60%
```

**æ¶ˆè´¹è€…æ€§èƒ½**ï¼š
```bash
# ä½¿ç”¨kafka-consumer-perf-testæµ‹è¯•
kafka-consumer-perf-test \
  --topic qywx-chat-messages \
  --messages 100000 \
  --group perf-test-group \
  --bootstrap-server $BROKERS

# æœŸæœ›ç»“æœï¼š
# - ååé‡ï¼š8000+ msgs/sec
# - PartitionCommitGateç§¯å‹ï¼š< 100
# - å¤„ç†å»¶è¿ŸP99ï¼š< 100ms
```

### 8.2 å‹åŠ›æµ‹è¯•åœºæ™¯

**åœºæ™¯1ï¼šå¤§ç”¨æˆ·é‡å¹¶å‘**
```go
// æ¨¡æ‹Ÿ1000ä¸ªç”¨æˆ·åŒæ—¶å‘é€æ¶ˆæ¯
func TestHighConcurrency(t *testing.T) {
    producer, _ := NewMessageProducer(brokers, topic)
    defer producer.Close()

    var wg sync.WaitGroup
    for userID := 0; userID < 1000; userID++ {
        wg.Add(1)
        go func(uid int) {
            defer wg.Done()
            for msgID := 0; msgID < 100; msgID++ {
                msg := generateTestMessage(fmt.Sprintf("user_%d", uid))
                producer.ProduceMessage(msg)
            }
        }(userID)
    }
    wg.Wait()

    // éªŒè¯ï¼šæ‰€æœ‰æ¶ˆæ¯æŒ‰ç”¨æˆ·é¡ºåºå¤„ç†
    // éªŒè¯ï¼šæ— æ¶ˆæ¯ä¸¢å¤±ï¼ˆé€šè¿‡offsetè¿ç»­æ€§æ£€æŸ¥ï¼‰
}
```

**åœºæ™¯2ï¼šRebalanceå‹åŠ›æµ‹è¯•**
```bash
# åŠ¨æ€æ‰©ç¼©å®¹æµ‹è¯•
for i in {1..5}; do
    echo "å¯åŠ¨æ¶ˆè´¹è€…å®ä¾‹ $i"
    go run consumer_test.go --group qywx-test &
    sleep 30

    echo "æ£€æŸ¥rebalanceçŠ¶æ€"
    kafka-consumer-groups --bootstrap-server $BROKERS --describe --group qywx-test

    echo "åœæ­¢æ¶ˆè´¹è€…å®ä¾‹ $((i-1))"
    kill $prev_pid
    sleep 30
done

# éªŒè¯ï¼šæ— æ¶ˆæ¯é‡å¤/ä¸¢å¤±
# éªŒè¯ï¼šPartitionCommitGateæ­£ç¡®å†²åˆ·
```

---

## 9. æ€»ç»“

**ğŸ”´ è‡´å‘½é—®é¢˜ä¿®å¤**ï¼š
1. **PartitionCommitGate**å½»åº•è§£å†³åˆ†åŒºå†…è¿ç»­æäº¤é—®é¢˜ï¼Œæ¶ˆé™¤ä¸¢æ¶ˆæ¯é£é™©
2. **é…ç½®é”®ä¿®æ­£**ä½¿ç”¨librdkafkaæ­£ç¡®é…ç½®ï¼Œç¡®ä¿å‚æ•°å®é™…ç”Ÿæ•ˆ
3. **ç»Ÿä¸€åˆ†åŒºå™¨**ä¿è¯è·¨è¯­è¨€åˆ†åŒºä¸€è‡´æ€§ï¼ŒDLQå›æµè·¯ç”±æ­£ç¡®
4. **MySQLå…œåº•æœºåˆ¶**ï¼ˆTODOï¼‰ä¸‰çº§é™çº§ä¿æŠ¤ï¼Œç¡®ä¿æ¶ˆæ¯æ°¸ä¸ä¸¢å¤±

**ğŸŸ¡ å¤æ‚åº¦å¤§å¹…ç®€åŒ–**ï¼š
1. **ç§»é™¤ç‰¹æ®Šæƒ…å†µ**ï¼šåºŸé™¤å¤æ‚é™çº§é€»è¾‘ã€å¤šå±‚ç†”æ–­å™¨ã€UserProcessorçŠ¶æ€æœº
2. **DLQæç®€åŒ–**ï¼šä»ç†è®ºå®Œç¾çš„æ¢å¤ç³»ç»Ÿç®€åŒ–ä¸ºå®ç”¨çš„æ­»ä¿¡é˜Ÿåˆ—
3. **ç»Ÿä¸€é…ç½®**ï¼šåŸºäºkmqæ ‡å‡†å®ç°ï¼Œå¼€å‘/ç”Ÿäº§ç¯å¢ƒä¸€è‡´

**ğŸŸ¢ æ¶æ„è´¨é‡æå‡**ï¼š
1. **æ•°æ®ç»“æ„ä¼˜å…ˆ**ï¼šPartitionCommitGateä½œä¸ºæ ¸å¿ƒï¼Œå…¶ä»–é€»è¾‘å›´ç»•å®ƒç®€åŒ–
2. **å®ç”¨ä¸»ä¹‰è®¾è®¡**ï¼šç›´æ¥ä½¿ç”¨confluent-kafka-goæœ€ä½³å®è·µï¼Œé¿å…é‡å¤é€ è½®å­
3. **é›¶ç ´åæ€§è¿ç§»**ï¼šä¿æŒä¸šåŠ¡APIä¸å˜ï¼Œå†…éƒ¨å®ç°å¹³æ»‘å‡çº§

---

## 10. è®¾è®¡æ·±åŒ–ä¸å®æ–½è®¡åˆ’ï¼ˆä¸¥æ ¼æœ‰åº + Kafka æ¥å…¥è½åœ°ï¼‰

### 10.1 ç»“è®ºä¸ç›®æ ‡
- åŒä¸€ç”¨æˆ·ï¼ˆexternal_user_idï¼‰ä¸¥æ ¼æœ‰åºæ˜¯åˆšæ€§è¦æ±‚ï¼›ä¿æŒâ€œæ¯ç”¨æˆ·ä¸€ä¸ª Processor goroutine ä¸²è¡Œå¤„ç†â€çš„æ—¢æœ‰æ¶æ„ä¸å˜ã€‚
- ç”¨ Kafka æ›¿ä»£å†…å­˜é€šé“ï¼Œæ ¸å¿ƒæ˜¯â€œå¤„ç†å®Œæˆâ†’å†æ¨è¿›åˆ†åŒº offset æäº¤â€ï¼Œå½¢æˆå¯é é—­ç¯ï¼›ç”Ÿäº§ç«¯æ¶ˆè´¹ DR äº‹ä»¶ï¼Œæ‰€æœ‰å¼‚æ­¥æŠ•é€’å¤±è´¥å†™å…¥ DLQã€‚

### 10.2 æ•°æ®æµä¸æ§åˆ¶ç‚¹ï¼ˆç«¯åˆ°ç«¯ï¼‰
- ç”Ÿäº§ï¼šå¾®ä¿¡å›è°ƒâ†’Kafka Producerï¼ˆKey=external_user_idï¼Œpartitioner=murmur2_randomï¼‰â†’Topic
- æ¶ˆè´¹ï¼šKafka Consumerï¼ˆcooperative-sticky, æ‰‹åŠ¨ store/commitï¼‰â†’ å°†æ¶ˆæ¯åŒ…è£…ä¸º Envelope æŠ•é€’åˆ° Scheduler.dispatchMessageï¼ˆé©±åŠ¨æ¯ç”¨æˆ· Processor ä¸²è¡Œå¤„ç†ï¼‰â†’ å¤„ç†å®Œæˆè§¦å‘ ack â†’ PartitionCommitGate.MarkDone + æ‰¹é‡ StoreOffsets/CommitOffsets
- DLQï¼š
  - ç”Ÿäº§ç«¯ï¼šDR å¤±è´¥â†’DLQï¼ˆKey ä¸ Header é€ä¼ ï¼Œä¾¿äºå›æ”¾ï¼‰
  - æ¶ˆè´¹ç«¯ï¼šä¸šåŠ¡ä¸å¯æ¢å¤â†’DLQï¼ˆhandled=trueï¼Œæ¨è¿› gateï¼‰

### 10.3 kmq å¢å¼ºï¼ˆå·²æ›´æ–°ï¼‰
- ç”Ÿäº§è€…ï¼ˆ/Users/peter/projs/libs/mq/kmq/producer.goï¼‰
  - é¡¶å±‚é…ç½® `partitioner="murmur2_random"`ï¼Œå¼ƒç”¨ `default.topic.config`ã€‚
  - å¼€å¯ `statistics.interval.ms=60000`ï¼Œ`go.delivery.report.fields="key,value,headers"`ã€‚
  - æ–°å¢ `AttachDLQ(*DLQ)`ï¼šDR å¤±è´¥è‡ªåŠ¨å†™å…¥ DLQï¼ˆä½¿ç”¨åŒ Keyã€Headersï¼‰ï¼Œé¿å…é™é»˜ä¸¢å¤±ã€‚
- æ¶ˆè´¹è€…ï¼ˆ/Users/peter/projs/libs/mq/kmq/consumer.goï¼‰
  - æ–°å¢ `PollAndDispatchWithAck(handler func(m *kafka.Message, ack func(success bool)), pollMs int)`ï¼š
    - handler å°†æ¶ˆæ¯æŠ•é€’ç»™æ¯ç”¨æˆ· Processorï¼›å¾… Processor çœŸå®å¤„ç†å®Œæˆåè°ƒç”¨ `ack(true)`ï¼Œè¿›è€Œ `gate.MarkDoneâ†’Batch.Storeâ†’å®šæ—¶/é˜ˆå€¼ Commit()`ã€‚
    - ack å…·å¤‡å¹‚ç­‰ä¿æŠ¤ï¼ˆ`sync.Once`ï¼‰ã€‚
  - ç»§ç»­æ”¯æŒç°æœ‰ `PollAndDispatch`ï¼ˆè¿”å› handled çš„è€æ¥å£ï¼‰ï¼Œä¾¿äºæ¸è¿›è¿ç§»ã€‚
  - Rebalanceï¼šAssigned ç”¨ `Committed()` ä½œä¸º gate èµ·ç‚¹ï¼ˆä½æ°´ä½ä¸ºå¤‡ï¼‰ï¼›Revoked å…ˆ `CommitContiguous()` å† `IncrementalUnassign()`ï¼ˆå·²å®ç°ï¼‰ã€‚

### 10.4 ä¸ Scheduler å¯¹æ¥ï¼ˆä¸¥æ ¼æœ‰åºä¿æŒä¸å˜ï¼‰
- ç°çŠ¶ï¼š`schedule.dispatcher()` å°†æ¶ˆæ¯æŒ‰ userID è·¯ç”±åˆ° `processors[userID].messageChan`ï¼ŒProcessor.run() ä¸²è¡Œå¤„ç†ï¼ˆè§ schedule/schedule.go:124, :220ï¼›processor.go:17, :43ï¼‰ã€‚
- Kafka æ¥å…¥é€‚é…å±‚ï¼š
  - ä½¿ç”¨ `kmq.Consumer.PollAndDispatchWithAck`ï¼›åœ¨ handler å†…ï¼š
    1) å°† Kafka æ¶ˆæ¯è§£åŒ…ä¸º KFRecvMessageï¼›
    2) æŠ•é€’åˆ° `Scheduler.dispatchMessage`ï¼ˆæˆ–ç›´è¾¾ per-user `processor.messageChan`ï¼‰ï¼›
    3) åœ¨ Processor å¤„ç†æµçš„â€œçœŸå®å®Œæˆç‚¹â€ï¼ˆæˆåŠŸå¤„ç†æˆ–å†™å…¥ DLQï¼‰è°ƒç”¨ `ack(true)`ã€‚
  - è‹¥å› ä¸šåŠ¡åˆ¤å®šâ€œä¸å¯å¤„ç†ä¸”ä¸åº”æ¨è¿›â€ï¼Œè°ƒç”¨ `ack(false)`ï¼ˆé€šå¸¸ç”¨ä¸åˆ°ï¼Œå»ºè®®å¤±è´¥å°± DLQï¼‰ã€‚

ç¤ºæ„ä»£ç ï¼ˆæ¶ˆè´¹ç«¯ handler ä¾§ä¼ªç ï¼‰ï¼š
```go
handler := func(m *kafka.Message, ack func(bool)) {
    var chatMsg ChatMessage
    if err := json.Unmarshal(m.Value, &chatMsg); err != nil {
        _ = dlq.Send(m.Key, m.Value, m.Headers)
        ack(true) // å·²å®‰å…¨è½DLQï¼Œæ¨è¿›gate
        return
    }

    // å°†æ¶ˆæ¯æŠ•é€’åˆ° Schedulerï¼ˆæ¯ç”¨æˆ·ä¸²è¡Œï¼‰
    delivered := tryDispatchToScheduler(&chatMsg, func onDone(success bool) { ack(success) })
    if !delivered {
        // æ— æ³•æŠ•é€’æ—¶å¯é™çº§DLQï¼Œé¿å…é˜»å¡æäº¤æ¨è¿›
        _ = dlq.Send(m.Key, m.Value, m.Headers)
        ack(true)
    }
}

go consumer.PollAndDispatchWithAck(handler, 100)
```

### 10.5 ç”Ÿäº§è€…ä¸ DLQ ç­–ç•¥
- Producerï¼š`acks=all`, `enable.idempotence=true`, `message.timeout.ms=30000`ï¼Œ`partitioner=murmur2_random`ã€‚
- äº‹ä»¶å¾ªç¯æ¶ˆè´¹ DRï¼šä¸€æ—¦ `msg.TopicPartition.Error != nil` â†’ å†™ DLQï¼ŒHeaders é€ä¼ ï¼›å…³é—­å‰ `Flush()` ç¡®ä¿å‡ºæ¸…ã€‚
- DLQï¼šä¸ä¸» Topic åŒ Key/åˆ†åŒºå™¨ï¼Œå›æ”¾å‘½ä¸­åŸåˆ†åŒºï¼›æ¶ˆæ¯ç»“æ„å»ºè®®åŒ…å« original_topic/partition/offset/reason/versionã€‚

### 10.6 å¯è§‚æµ‹æ€§ä¸å‘Šè­¦
- ç”Ÿäº§ï¼šDR å¤±è´¥ç‡ã€Flush å‰©ä½™ã€é˜Ÿåˆ—æ·±åº¦ã€ååï¼›å¯¼å‡º librdkafka Stats JSONï¼ˆ`statistics.interval.ms` å·²å¯ç”¨ï¼‰ã€‚
- æ¶ˆè´¹ï¼šgate backlogã€æäº¤æ»åï¼ˆhigh watermark - committedï¼‰ã€rebalance æ¬¡æ•°ã€æ¯ç”¨æˆ·å¤„ç†æ—¶å»¶ P99ã€DLQ å†™å…¥ç‡ã€‚
- å‘Šè­¦ï¼š
  - gate backlog/æäº¤æ»åæŒç»­è¶…é˜ˆï¼ˆä¾‹å¦‚ > 60sï¼‰ã€‚
  - DR å¤±è´¥ç‡å¼‚å¸¸ä¸Šå‡ã€DLQ çˆ†é‡ã€‚

### 10.7 é…ç½®åŸºçº¿ï¼ˆlibrdkafkaï¼‰
- Producer å…³é”®ï¼š`acks=all`, `enable.idempotence=true`, `message.timeout.ms=30000`, `partitioner=murmur2_random`, `go.delivery.report.fields=key,value,headers`ã€‚
- Consumer å…³é”®ï¼š`enable.auto.commit=false`, `enable.auto.offset.store=false`, `partition.assignment.strategy=cooperative-sticky`, `auto.offset.reset=earliest`, `statistics.interval.ms=60000`ã€‚

### 10.8 è¿ç§»ä¸æ¼”ç»ƒ
- Phase 0ï¼ˆåŒå†™ï¼‰ï¼šä¿ç•™ç°æœ‰é€šé“ä¸»è·¯å¾„ï¼ŒåŒæ—¶ Producer åŒå†™ Kafkaï¼ŒéªŒè¯ DRâ†’DLQ é—­ç¯ä¸ååã€‚
- Phase 1ï¼ˆæ—è·¯æ¶ˆè´¹ï¼‰ï¼šConsumer è¯»å– Kafkaâ†’ä»…è½æ—¥å¿—æˆ–æ‰§è¡Œä¸šåŠ¡ä½†ä¸æäº¤ï¼Œç”¨äºç¨³å®šæ€§éªŒè¯ã€‚
- Phase 2ï¼ˆåˆ‡æ¢ï¼‰ï¼šå¯ç”¨ `PollAndDispatchWithAck`ï¼Œä»¥ ack ä¸ºå‡†æ¨è¿›æäº¤ï¼›ä¿ç•™å¿«é€Ÿå›æ»šå¼€å…³ã€‚
- æ··æ²Œ/æ¼”ç»ƒï¼šæ–­ç½‘ã€broker é‡å¯ã€æ‰©ç¼©å®¹ï¼›éªŒè¯ revoked å†²åˆ·ã€assigned è¿ç»­æ€§ã€DR å¤±è´¥â†’DLQã€‚

### 10.9 éªŒæ”¶æ ‡å‡†
- é¡ºåºæ€§ï¼šåŒä¸€ external_user_id çš„å¤„ç†æ—¥å¿—ä¸ä¸šåŠ¡å‰¯ä½œç”¨ä¸¥æ ¼é€’å¢ï¼Œæ— ä¹±åºï¼›è·¨ Key å¹¶å‘ä¸ä¸²æ‰°ã€‚
- å¯é æ€§ï¼šç”Ÿäº§ç«¯æ— é™é»˜ä¸¢å¤±ï¼ˆDRâ†’DLQï¼‰ï¼›æ¶ˆè´¹ç«¯ gate backlog å¯æ§ã€æäº¤æ›²çº¿è¿ç»­ï¼›Rebalance æ— ä¸¢å¤±/æ— é™é‡å¤ã€‚
- æ€§èƒ½ï¼šæ»¡è¶³ 100â†’500 å¹¶å‘ç”¨æˆ·ç›®æ ‡ä¸‹çš„ P99 æŒ‡æ ‡ï¼ˆç”Ÿäº§<50msã€å¤„ç†<100msï¼‰ï¼Œå¹¶æä¾›æ‰©å®¹å‡†åˆ™ã€‚

### 10.10 åç»­å¯é€‰å¢å¼º
- äº‹åŠ¡/EOSï¼šè‹¥å‡ºç°â€œConsumeâ†’Produceâ€ä¸”è¦æ±‚è·¨ Topic åŸå­æ€§ï¼Œè¯„ä¼° transactional.id + SendOffsetsToTransactionã€‚
- å›æ”¾å·¥å…·ï¼šDLQâ†’ä¸»Topic é€‰æ‹©æ€§å›æ”¾ï¼ˆæŒ‰ user/time/åŸå› ï¼‰ï¼›å†™å…¥ `replayed=true` headerã€‚

### 10.11 å‚è€ƒç¤ºä¾‹ï¼ˆå¯ç›´æ¥è¿è¡Œï¼‰
- è·¯å¾„ï¼š`/Users/peter/projs/example/kafka-bridge`
  - `producer/main.go`ï¼šæ¼”ç¤º acks=all + å¹‚ç­‰ + DRâ†’DLQã€‚
  - `consumer/main.go`ï¼ˆç”Ÿäº§å¯¹æ¥å…¥å£ï¼Œæ¨èï¼‰ï¼šæ¼”ç¤ºæ‰‹åŠ¨ store/commitã€cooperative-stickyã€ack(true) æ‰æ¨è¿›æäº¤ï¼ˆä½¿ç”¨æ‰¹é‡æäº¤ç®¡ç†ï¼Œé¿å…â€œå®Œæˆå³æäº¤â€ï¼‰ã€‚
  - `adapter/scheduler_adapter.go`ï¼šæŒ‰ç”¨æˆ·ä¸²è¡Œé€‚é…å™¨ï¼Œæš´éœ² onResult(err) â†’ åœ¨å…¶ä¸­è§¦å‘ ack(true)ã€‚
  - `types/commit_gate.go`ï¼šåˆ†åŒºæäº¤é—¸é—¨ç¤ºä¾‹å®ç°ã€‚
  - `consumer-mock/main.go` ä¸ `scheduler/mock.go`ï¼ˆä»…æ¼”ç¤º/è”è°ƒï¼Œç¦æ­¢ç”¨äºç”Ÿäº§ï¼‰ï¼šä½¿ç”¨ mock Schedulerï¼ˆæ¯ç”¨æˆ· goroutineï¼‰å¤ç° onDone(err)â†’ack(true) çš„å®Œæˆç‚¹ï¼Œé…åˆæ‰¹é‡æäº¤ç®¡ç†ã€‚
  - è¿è¡Œæ–¹å¼ä¸è¯´æ˜è§ `README.md`ã€‚
